{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gbQXBqtkYea"
      },
      "source": [
        "## Inisialisasi Library untuk Tahap Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Import library**\n",
        "  - `pickle` → membaca model dan artefak yang sudah disimpan.  \n",
        "  - `numpy` → manipulasi array dan operasi numerik.  \n",
        "- **Nonaktifkan peringatan** untuk menjaga output tetap bersih saat proses inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pVN7Kg2ckb1R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Library yang dibutuhkan untuk inference berhasil di-import.\n"
          ]
        }
      ],
      "source": [
        "# Mengimpor library untuk membaca file model dan artefak yang disimpan\n",
        "import pickle\n",
        "\n",
        "# Mengimpor library untuk manipulasi array dan operasi numerik\n",
        "import numpy as np\n",
        "\n",
        "# Menonaktifkan peringatan agar output lebih bersih\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"Library yang dibutuhkan untuk inference berhasil di-import.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PyHmtp6kdhE"
      },
      "source": [
        "## Memuat Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sebelum melakukan **inference**, kita perlu memuat kembali artefak yang sebelumnya disimpan di `../Models`:\n",
        "\n",
        "- **Model Ensemble Terbaik** (`best_ensemble_model.pkl`) → model pemenang hasil evaluasi.\n",
        "- **TF-IDF Vectorizer** (`tfidf_vectorizer.pkl`) → mengubah teks mentah menjadi vektor numerik.\n",
        "- **Feature Selector** (`feature_selector.pkl`) → memilih fitur paling relevan dari hasil TF-IDF.\n",
        "\n",
        "Semua komponen ini akan digunakan bersama untuk memproses teks baru dan menghasilkan prediksi.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjpwKr-hkhRB",
        "outputId": "32dc0dd5-a436-475d-9eeb-72afdcb6c78f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model terbaik, TF-IDF Vectorizer, dan Feature Selector berhasil dimuat.\n"
          ]
        }
      ],
      "source": [
        "# Membuka dan memuat model ensemble terbaik dari file pickle\n",
        "with open(\"../Models/best_ensemble_model.pkl\", \"rb\") as f:\n",
        "    best_model = pickle.load(f)\n",
        "\n",
        "# Memuat kembali TF-IDF Vectorizer untuk mentransformasi teks\n",
        "with open(\"../Models/tfidf_vectorizer.pkl\", \"rb\") as f:\n",
        "    tfidf_vectorizer = pickle.load(f)\n",
        "\n",
        "# Memuat kembali Feature Selector untuk memilih fitur yang relevan\n",
        "with open(\"../Models/feature_selector.pkl\", \"rb\") as f:\n",
        "    feature_selector = pickle.load(f)\n",
        "\n",
        "print(\"Model terbaik, TF-IDF Vectorizer, dan Feature Selector berhasil dimuat.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbqiSsRVkizq"
      },
      "source": [
        "## Preprocessing Untuk Data Baru"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tahap ini mempersiapkan teks mentah sebelum diprediksi oleh model terbaik.  \n",
        "Proses yang dilakukan dalam fungsi `preprocess_for_inference` meliputi:\n",
        "\n",
        "1. **Case Folding** → mengubah semua huruf menjadi lowercase.\n",
        "2. **Normalisasi Slang** → mengganti kata tidak baku berdasarkan kamus `slangwords.json`.\n",
        "3. **Stopword Removal** → menghapus kata umum yang tidak membawa makna signifikan.\n",
        "4. **Tokenisasi & Filtering** → memisahkan teks menjadi kata dan membuang karakter non-alfanumerik.\n",
        "5. **Stemming** → mengubah kata ke bentuk dasarnya menggunakan *Sastrawi Stemmer*.\n",
        "\n",
        "Hasil akhir preprocessing ini kemudian:\n",
        "- **Ditransformasikan** ke bentuk vektor numerik menggunakan **TF-IDF Vectorizer**.\n",
        "- **Disaring** menggunakan **Feature Selector** agar hanya fitur relevan yang dipakai untuk prediksi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t08BsG7gkl8Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teks setelah preprocessing:\n",
            "1. produk bagus\n",
            "2. layan lambat kecewa\n",
            "3. harga mahal kualitas\n",
            "\n",
            "Dimensi fitur setelah TF-IDF dan Feature Selection: (3, 2000)\n",
            "Data baru siap untuk diprediksi.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import json\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Data teks baru yang akan digunakan untuk prediksi sentimen\n",
        "new_texts = [\n",
        "    \"Produk ini sangat bagus!\",                      # Ekspektasi: positif\n",
        "    \"Pelayanan sangat lambat dan mengecewakan.\",      # Ekspektasi: negatif\n",
        "    \"Harganya cukup mahal tapi kualitasnya biasa saja.\" # Ekspektasi: negatif (karena model biner)\n",
        "]\n",
        "\n",
        "# --- Fungsi Tunggal untuk Preprocessing Teks Inference ---\n",
        "def preprocess_for_inference(texts):\n",
        "    # 1. Muat alat preprocessing yang diperlukan\n",
        "    with open('../Datasets/slangwords.json', 'r') as file:\n",
        "        slang_dict = json.load(file)\n",
        "    stop_words = set(stopwords.words('indonesian'))\n",
        "    stemmer = StemmerFactory().create_stemmer()\n",
        "\n",
        "    # 2. Proses setiap teks dalam list\n",
        "    processed_texts = []\n",
        "    for text in texts:\n",
        "        text = text.lower() # Case folding\n",
        "        # Normalisasi slang\n",
        "        words = text.split()\n",
        "        normalized_words = [slang_dict.get(word, word) for word in words]\n",
        "        text = ' '.join(normalized_words)\n",
        "        # Hapus stopwords\n",
        "        words = word_tokenize(text)\n",
        "        filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "        text = ' '.join(filtered_words)\n",
        "        # Stemming\n",
        "        text = stemmer.stem(text)\n",
        "        processed_texts.append(text)\n",
        "    \n",
        "    return processed_texts\n",
        "\n",
        "# --- Jalankan Pipeline ---\n",
        "# 1. Bersihkan teks mentah\n",
        "preprocessed_texts = preprocess_for_inference(new_texts)\n",
        "print(\"Teks setelah preprocessing:\")\n",
        "for i, text in enumerate(preprocessed_texts):\n",
        "    print(f\"{i+1}. {text}\")\n",
        "\n",
        "# 2. Terapkan Vectorizer dan Feature Selector yang sudah dimuat\n",
        "new_tfidf = tfidf_vectorizer.transform(preprocessed_texts)\n",
        "new_features_selected = feature_selector.transform(new_tfidf)\n",
        "\n",
        "print(f\"\\nDimensi fitur setelah TF-IDF dan Feature Selection: {new_features_selected.shape}\")\n",
        "print(\"Data baru siap untuk diprediksi.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQT8z_M1koGF"
      },
      "source": [
        "## Prediksi Sentimen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Pada tahap ini, **model terbaik** yang telah dimuat digunakan untuk memprediksi sentimen data teks baru yang sudah melalui preprocessing, TF-IDF, dan feature selection.\n",
        "\n",
        "Output yang dihasilkan:\n",
        "- **Format numerik**: `1` untuk sentimen positif, `0` untuk sentimen negatif."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RuBx-nwkrKo",
        "outputId": "3f4c10f2-4afb-471b-b990-b5e22f46cabe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediksi berhasil dilakukan.\n",
            "Hasil prediksi (dalam format numerik): [1 0 0]\n"
          ]
        }
      ],
      "source": [
        "# Menggunakan model terbaik yang telah dimuat untuk memprediksi sentimen\n",
        "predictions = best_model.predict(new_features_selected)\n",
        "\n",
        "print(\"Prediksi berhasil dilakukan.\")\n",
        "print(\"Hasil prediksi (dalam format numerik):\", predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umDvxX5Gks6h"
      },
      "source": [
        "## Konversi Prediksi ke Label Sentimen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tahap ini mengubah hasil prediksi **numerik** (`0` = negatif, `1` = positif) menjadi **label string** yang lebih mudah dibaca.  \n",
        "Hasil akhir ditampilkan per kalimat input, lengkap dengan teks aslinya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHgbS6IJkvEV",
        "outputId": "7e0b031a-855d-4ac9-dbb6-f4bfd43bfb45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Hasil Prediksi Sentimen ---\n",
            "\n",
            "Teks Asli: \"Produk ini sangat bagus!\"\n",
            "Prediksi Sentimen: POSITIF\n",
            "----------------------------------------\n",
            "\n",
            "Teks Asli: \"Pelayanan sangat lambat dan mengecewakan.\"\n",
            "Prediksi Sentimen: NEGATIF\n",
            "----------------------------------------\n",
            "\n",
            "Teks Asli: \"Harganya cukup mahal tapi kualitasnya biasa saja.\"\n",
            "Prediksi Sentimen: NEGATIF\n",
            "----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Mapping label numerik (0 dan 1) ke label string yang mudah dibaca.\n",
        "label_map = {0: \"negatif\", 1: \"positif\"}\n",
        "\n",
        "# Menampilkan hasil prediksi dari model terbaik untuk setiap kalimat input.\n",
        "print(\"\\n--- Hasil Prediksi Sentimen ---\")\n",
        "for i, text in enumerate(new_texts):\n",
        "    predicted_label_numeric = predictions[i]\n",
        "    predicted_label_string = label_map[predicted_label_numeric]\n",
        "    \n",
        "    print(f\"\\nTeks Asli: \\\"{text}\\\"\")\n",
        "    print(f\"Prediksi Sentimen: {predicted_label_string.upper()}\")\n",
        "    print(\"-\" * 40)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
